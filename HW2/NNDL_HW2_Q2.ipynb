{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV9O0KYBMl4m",
        "outputId": "deae2624-2771-41a2-9be2-6a17bd32f47a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y33O7MQPwomW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from keras.datasets import fashion_mnist\n",
        "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy, BinaryPrecision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "hHDdAgcvw8_p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(trainy.shape)\n",
        "print(testy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP4Ja03txLSL",
        "outputId": "17c08b82-e570-4aa8-bd19-290a311c893c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNArch5(nn.Module):\n",
        "  def __init__(self,K):\n",
        "    super(CNNArch5,self).__init__()\n",
        "    self.convs = nn.Sequential(\n",
        "        nn.Conv2d(1,32,3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,32,3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Conv2d(32,64,3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Dropout(p=0.25),\n",
        "    )\n",
        "    self.deep=nn.Sequential(\n",
        "        nn.Linear(1024,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512,K)\n",
        "    )\n",
        "\n",
        "  def forward(self,X):\n",
        "    out=self.convs(X)\n",
        "    #print(out.shape)\n",
        "    out=out.view(out.size(0),-1)\n",
        "    out=self.deep(out)\n",
        "    return out\n",
        "\n",
        "class CNNArch4(nn.Module):\n",
        "  def __init__(self,K):\n",
        "    super(CNNArch4,self).__init__()\n",
        "    self.convs = nn.Sequential(\n",
        "        nn.Conv2d(1,64,2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Conv2d(64,64,2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Conv2d(64,64,2),\n",
        "        nn.Dropout(p=0.25)\n",
        "    )\n",
        "    self.deep=nn.Sequential(\n",
        "        nn.Linear(1600,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Linear(64, K)\n",
        "    )\n",
        "  \n",
        "  def forward(self,X):\n",
        "    out=self.convs(X)\n",
        "    out=out.view(out.size(0),-1)\n",
        "    out=self.deep(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "oN5w_NACxN5K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets=np.zeros((60000,10))\n",
        "for j in range(60000):\n",
        "  targets[j][trainy[j]]=1\n",
        "targets=torch.tensor(targets)\n",
        "test_tar=np.zeros((10000,10))\n",
        "for j in range(10000):\n",
        "  test_tar[j][testy[j]]=1\n",
        "test_tar=torch.tensor(test_tar)"
      ],
      "metadata": {
        "id": "bOwqRgCLzNSt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myloader():\n",
        "    def __init__(self, x,y):\n",
        "        self.x=x\n",
        "        self.y=y\n",
        "        # transform_list += [transforms.Normalize(mean=[0.5], std=[0.5])]\n",
        "        # preprocess = transforms.Compose(transform_list)\n",
        "        # self.preprocess = preprocess\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        # t=torch.zeros(10,dtype=torch.float32)\n",
        "        # t[self.dataset.targets[idx].item()]=1\n",
        "        # return self.preprocess(self.dataset.data[idx].numpy()), t\n",
        "        return self.x[idx],self.y[idx]"
      ],
      "metadata": {
        "id": "BDwvSevnW6dq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = CNNArch5(10)\n",
        "model = CNNArch4(10)"
      ],
      "metadata": {
        "id": "6FY9wzSJy8-1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7qu2WxRzByo",
        "outputId": "8b445043-1d2b-4591-c4a8-4d33b714f53e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNArch4(\n",
              "  (convs): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "    (4): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.25, inplace=False)\n",
              "    (8): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (9): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (deep): Sequential(\n",
              "    (0): Linear(in_features=1600, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.25, inplace=False)\n",
              "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX=torch.tensor(trainX,dtype=torch.float32)\n",
        "targets=torch.tensor(targets,dtype=torch.float32)\n",
        "targets=targets.to(device)\n",
        "testX=torch.tensor(testX,dtype=torch.float32)\n",
        "test_tar=torch.tensor(test_tar,dtype=torch.float32)\n",
        "test_tar=test_tar.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCVrn7T9zgU_",
        "outputId": "34fc00f3-75d4-423f-96dd-4c083c6eab14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim=torch.optim.Adam(model.parameters())\n",
        "#optim=torch.optim.SGD(model.parameters(),lr=0.001)\n",
        "\n",
        "cri=nn.CrossEntropyLoss()\n",
        "los_min=10\n",
        "cur_loss=10\n",
        "m_los=10"
      ],
      "metadata": {
        "id": "hjoqQ9Gp0gGX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX=trainX.unsqueeze(1)\n",
        "print(trainX.shape)\n",
        "testX=testX.unsqueeze(1)\n",
        "print(testX.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVK2auyc1H_R",
        "outputId": "91c2687b-8fea-49e8-9367-a3ee5f3f62c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX=trainX.to(device)\n",
        "testX=testX.to(device)"
      ],
      "metadata": {
        "id": "z8wB18-I2EA4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = myloader(trainX,targets)\n",
        "test_loader = myloader(testX,test_tar)\n",
        "\n",
        "train=torch.utils.data.DataLoader(train_loader,128,True)\n",
        "test=torch.utils.data.DataLoader(test_loader,128,False)\n",
        "\n",
        "metric = BinaryF1Score()\n",
        "metric1 = BinaryAccuracy()\n",
        "metric2 = BinaryPrecision()\n",
        "\n",
        "softmax = nn.Softmax(dim=1)"
      ],
      "metadata": {
        "id": "StlqzJ14Yjaf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=50\n",
        "for epoch in range(n):\n",
        "  los_train = []\n",
        "  los_test = []\n",
        "  f1_list = []\n",
        "  acc_list = []\n",
        "  pre_list = []\n",
        "\n",
        "  model.train()\n",
        "  for data, target in train:\n",
        "    optim.zero_grad()\n",
        "    out=model(data)\n",
        "    loss=cri(out,target)\n",
        "    los_train.append(loss.item())\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "  print(f'epoch {epoch} train loss : {sum(los_train) / len(los_train)}')\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, target in test:  \n",
        "      outt = softmax(model(data))\n",
        "      cur_loss=cri(outt, target)\n",
        "      los_test.append(cur_loss.item())\n",
        "\n",
        "      f1_list.append(metric(outt.cpu(), target.cpu()))\n",
        "      acc_list.append(metric1(outt.cpu(), target.cpu()))\n",
        "      pre_list.append(metric2(outt.cpu(), target.cpu()))\n",
        "\n",
        "    los_test_batch=sum(los_test) / len(los_test)\n",
        "    f1=sum(f1_list) / len(f1_list)\n",
        "    acc=sum(acc_list) / len(acc_list)\n",
        "    pre=sum(pre_list) / len(pre_list)\n",
        "\n",
        "    if(m_los>los_test_batch):\n",
        "      print(f'epoch {epoch} Model Saved')\n",
        "      m_los=los_test_batch\n",
        "      torch.save(model,'best_model.pth')\n",
        "\n",
        "    print(f'epoch {epoch} test loss : {los_test_batch}')\n",
        "    print(f'epoch {epoch} F1 : {f1}')\n",
        "    print(f'epoch {epoch} Acc : {acc}')\n",
        "    print(f'epoch {epoch} Pre : {pre}')\n",
        "    print('*  *  *')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ3WUlGk0TI1",
        "outputId": "fd690df8-5abf-4e5b-ced7-77aafc8980e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train loss : 0.9055564664701409\n",
            "epoch 0 Model Saved\n",
            "epoch 0 test loss : 1.707338256171987\n",
            "epoch 0 F1 : 0.8085668683052063\n",
            "epoch 0 Acc : 0.9647646546363831\n",
            "epoch 0 Pre : 0.8835054039955139\n",
            "*  *  *\n",
            "epoch 1 train loss : 0.5343684748545893\n",
            "epoch 1 Model Saved\n",
            "epoch 1 test loss : 1.6745961889435974\n",
            "epoch 1 F1 : 0.8407801389694214\n",
            "epoch 1 Acc : 0.9702828526496887\n",
            "epoch 1 Pre : 0.9037508368492126\n",
            "*  *  *\n",
            "epoch 2 train loss : 0.47250969622180916\n",
            "epoch 2 Model Saved\n",
            "epoch 2 test loss : 1.6685869150523898\n",
            "epoch 2 F1 : 0.8484274744987488\n",
            "epoch 2 Acc : 0.9718749523162842\n",
            "epoch 2 Pre : 0.9179962873458862\n",
            "*  *  *\n",
            "epoch 3 train loss : 0.4267474533970168\n",
            "epoch 3 Model Saved\n",
            "epoch 3 test loss : 1.6325891380068622\n",
            "epoch 3 F1 : 0.87298583984375\n",
            "epoch 3 Acc : 0.9754451513290405\n",
            "epoch 3 Pre : 0.9035317301750183\n",
            "*  *  *\n",
            "epoch 4 train loss : 0.3942962234843769\n",
            "epoch 4 Model Saved\n",
            "epoch 4 test loss : 1.6294967418984523\n",
            "epoch 4 F1 : 0.8770711421966553\n",
            "epoch 4 Acc : 0.9763745665550232\n",
            "epoch 4 Pre : 0.9133422374725342\n",
            "*  *  *\n",
            "epoch 5 train loss : 0.38167389541038316\n",
            "epoch 5 Model Saved\n",
            "epoch 5 test loss : 1.6254988395715062\n",
            "epoch 5 F1 : 0.8806189894676208\n",
            "epoch 5 Acc : 0.9769281148910522\n",
            "epoch 5 Pre : 0.9117400646209717\n",
            "*  *  *\n",
            "epoch 6 train loss : 0.36674744929713227\n",
            "epoch 6 Model Saved\n",
            "epoch 6 test loss : 1.6230152000354816\n",
            "epoch 6 F1 : 0.8804546594619751\n",
            "epoch 6 Acc : 0.9768494367599487\n",
            "epoch 6 Pre : 0.910140872001648\n",
            "*  *  *\n",
            "epoch 7 train loss : 0.3546263358549777\n",
            "epoch 7 Model Saved\n",
            "epoch 7 test loss : 1.610365620142297\n",
            "epoch 7 F1 : 0.8879371285438538\n",
            "epoch 7 Acc : 0.978273332118988\n",
            "epoch 7 Pre : 0.9165080785751343\n",
            "*  *  *\n",
            "epoch 8 train loss : 0.3487232293782712\n",
            "epoch 8 test loss : 1.6115441835379298\n",
            "epoch 8 F1 : 0.89299076795578\n",
            "epoch 8 Acc : 0.979242742061615\n",
            "epoch 8 Pre : 0.9205135703086853\n",
            "*  *  *\n",
            "epoch 9 train loss : 0.34209427669612585\n",
            "epoch 9 Model Saved\n",
            "epoch 9 test loss : 1.608523865289326\n",
            "epoch 9 F1 : 0.8936817646026611\n",
            "epoch 9 Acc : 0.9793117642402649\n",
            "epoch 9 Pre : 0.9185724258422852\n",
            "*  *  *\n",
            "epoch 10 train loss : 0.3327956995539574\n",
            "epoch 10 Model Saved\n",
            "epoch 10 test loss : 1.6041733403749103\n",
            "epoch 10 F1 : 0.8967605829238892\n",
            "epoch 10 Acc : 0.9799940586090088\n",
            "epoch 10 Pre : 0.9259566068649292\n",
            "*  *  *\n",
            "epoch 11 train loss : 0.3293321258477819\n",
            "epoch 11 Model Saved\n",
            "epoch 11 test loss : 1.598072026349321\n",
            "epoch 11 F1 : 0.8977639079093933\n",
            "epoch 11 Acc : 0.980013906955719\n",
            "epoch 11 Pre : 0.918667197227478\n",
            "*  *  *\n",
            "epoch 12 train loss : 0.3231528571038358\n",
            "epoch 12 test loss : 1.6033864579623258\n",
            "epoch 12 F1 : 0.894845724105835\n",
            "epoch 12 Acc : 0.9795786142349243\n",
            "epoch 12 Pre : 0.9215152859687805\n",
            "*  *  *\n",
            "epoch 13 train loss : 0.3187911667739913\n",
            "epoch 13 Model Saved\n",
            "epoch 13 test loss : 1.5952034222928784\n",
            "epoch 13 F1 : 0.900114119052887\n",
            "epoch 13 Acc : 0.9804684519767761\n",
            "epoch 13 Pre : 0.9204581379890442\n",
            "*  *  *\n",
            "epoch 14 train loss : 0.3140567482979313\n",
            "epoch 14 test loss : 1.596773195870315\n",
            "epoch 14 F1 : 0.9000100493431091\n",
            "epoch 14 Acc : 0.980488657951355\n",
            "epoch 14 Pre : 0.921891987323761\n",
            "*  *  *\n",
            "epoch 15 train loss : 0.31306550558060725\n",
            "epoch 15 Model Saved\n",
            "epoch 15 test loss : 1.588618114024778\n",
            "epoch 15 F1 : 0.9015463590621948\n",
            "epoch 15 Acc : 0.9806962013244629\n",
            "epoch 15 Pre : 0.9192588925361633\n",
            "*  *  *\n",
            "epoch 16 train loss : 0.30656278374861046\n",
            "epoch 16 test loss : 1.6048028288008291\n",
            "epoch 16 F1 : 0.8889331817626953\n",
            "epoch 16 Acc : 0.9783623814582825\n",
            "epoch 16 Pre : 0.9126320481300354\n",
            "*  *  *\n",
            "epoch 17 train loss : 0.30136410996857993\n",
            "epoch 17 test loss : 1.5941089376618591\n",
            "epoch 17 F1 : 0.9042560458183289\n",
            "epoch 17 Acc : 0.9813093543052673\n",
            "epoch 17 Pre : 0.9260262846946716\n",
            "*  *  *\n",
            "epoch 18 train loss : 0.30357188596400114\n",
            "epoch 18 test loss : 1.5965623251999481\n",
            "epoch 18 F1 : 0.9027210474014282\n",
            "epoch 18 Acc : 0.9809830784797668\n",
            "epoch 18 Pre : 0.9230145812034607\n",
            "*  *  *\n",
            "epoch 19 train loss : 0.30167454045845754\n",
            "epoch 19 Model Saved\n",
            "epoch 19 test loss : 1.5879745302321036\n",
            "epoch 19 F1 : 0.9037732481956482\n",
            "epoch 19 Acc : 0.9811412692070007\n",
            "epoch 19 Pre : 0.9217013716697693\n",
            "*  *  *\n",
            "epoch 20 train loss : 0.2973604037372797\n",
            "epoch 20 Model Saved\n",
            "epoch 20 test loss : 1.5878032038483438\n",
            "epoch 20 F1 : 0.9056795239448547\n",
            "epoch 20 Acc : 0.9815269112586975\n",
            "epoch 20 Pre : 0.9246335625648499\n",
            "*  *  *\n",
            "epoch 21 train loss : 0.29281447192372034\n",
            "epoch 21 Model Saved\n",
            "epoch 21 test loss : 1.5823210764534865\n",
            "epoch 21 F1 : 0.9066084027290344\n",
            "epoch 21 Acc : 0.9816158413887024\n",
            "epoch 21 Pre : 0.9203771948814392\n",
            "*  *  *\n",
            "epoch 22 train loss : 0.29408790795470097\n",
            "epoch 22 test loss : 1.5893636625024337\n",
            "epoch 22 F1 : 0.9022476673126221\n",
            "epoch 22 Acc : 0.9808050990104675\n",
            "epoch 22 Pre : 0.9183961749076843\n",
            "*  *  *\n",
            "epoch 23 train loss : 0.292027789551312\n",
            "epoch 23 test loss : 1.5854186815551565\n",
            "epoch 23 F1 : 0.9072887301445007\n",
            "epoch 23 Acc : 0.9818335175514221\n",
            "epoch 23 Pre : 0.9257196187973022\n",
            "*  *  *\n",
            "epoch 24 train loss : 0.2885039115447734\n",
            "epoch 24 test loss : 1.5843215547030485\n",
            "epoch 24 F1 : 0.9033327698707581\n",
            "epoch 24 Acc : 0.98099285364151\n",
            "epoch 24 Pre : 0.9185713529586792\n",
            "*  *  *\n",
            "epoch 25 train loss : 0.2907701727868652\n",
            "epoch 25 Model Saved\n",
            "epoch 25 test loss : 1.5813737805885604\n",
            "epoch 25 F1 : 0.9075547456741333\n",
            "epoch 25 Acc : 0.9818038940429688\n",
            "epoch 25 Pre : 0.9218261241912842\n",
            "*  *  *\n",
            "epoch 26 train loss : 0.28711697220929394\n",
            "epoch 26 test loss : 1.5816245199758796\n",
            "epoch 26 F1 : 0.9100622534751892\n",
            "epoch 26 Acc : 0.9823278784751892\n",
            "epoch 26 Pre : 0.9258276224136353\n",
            "*  *  *\n",
            "epoch 27 train loss : 0.287340457060698\n",
            "epoch 27 Model Saved\n",
            "epoch 27 test loss : 1.576684373843519\n",
            "epoch 27 F1 : 0.9092506766319275\n",
            "epoch 27 Acc : 0.9821498394012451\n",
            "epoch 27 Pre : 0.9241742491722107\n",
            "*  *  *\n",
            "epoch 28 train loss : 0.28411742256902683\n",
            "epoch 28 test loss : 1.5821642151361779\n",
            "epoch 28 F1 : 0.9066303968429565\n",
            "epoch 28 Acc : 0.9815860986709595\n",
            "epoch 28 Pre : 0.918891429901123\n",
            "*  *  *\n",
            "epoch 29 train loss : 0.2820875592577432\n",
            "epoch 29 test loss : 1.5778405560722835\n",
            "epoch 29 F1 : 0.9094261527061462\n",
            "epoch 29 Acc : 0.982218861579895\n",
            "epoch 29 Pre : 0.9258016347885132\n",
            "*  *  *\n",
            "epoch 30 train loss : 0.2837240062098005\n",
            "epoch 30 test loss : 1.5770856594737572\n",
            "epoch 30 F1 : 0.9108741879463196\n",
            "epoch 30 Acc : 0.9824563264846802\n",
            "epoch 30 Pre : 0.9248697757720947\n",
            "*  *  *\n",
            "epoch 31 train loss : 0.2818385515131676\n",
            "epoch 31 Model Saved\n",
            "epoch 31 test loss : 1.5764539558676225\n",
            "epoch 31 F1 : 0.9066779017448425\n",
            "epoch 31 Acc : 0.9815961718559265\n",
            "epoch 31 Pre : 0.9187310338020325\n",
            "*  *  *\n",
            "epoch 32 train loss : 0.2816405756704843\n",
            "epoch 32 Model Saved\n",
            "epoch 32 test loss : 1.57634013061282\n",
            "epoch 32 F1 : 0.9116089344024658\n",
            "epoch 32 Acc : 0.9826245903968811\n",
            "epoch 32 Pre : 0.9265294075012207\n",
            "*  *  *\n",
            "epoch 33 train loss : 0.2746527054225966\n",
            "epoch 33 test loss : 1.5801720800279062\n",
            "epoch 33 F1 : 0.9070266485214233\n",
            "epoch 33 Acc : 0.9816654324531555\n",
            "epoch 33 Pre : 0.9191166162490845\n",
            "*  *  *\n",
            "epoch 34 train loss : 0.2726615682117212\n",
            "epoch 34 test loss : 1.5813584976558444\n",
            "epoch 34 F1 : 0.9139591455459595\n",
            "epoch 34 Acc : 0.9830893278121948\n",
            "epoch 34 Pre : 0.929896891117096\n",
            "*  *  *\n",
            "epoch 35 train loss : 0.27753268719227836\n",
            "epoch 35 test loss : 1.582669600655761\n",
            "epoch 35 F1 : 0.9099295735359192\n",
            "epoch 35 Acc : 0.9823178648948669\n",
            "epoch 35 Pre : 0.9265468716621399\n",
            "*  *  *\n",
            "epoch 36 train loss : 0.2729145976970953\n",
            "epoch 36 Model Saved\n",
            "epoch 36 test loss : 1.5760880557796624\n",
            "epoch 36 F1 : 0.9079331159591675\n",
            "epoch 36 Acc : 0.9818828105926514\n",
            "epoch 36 Pre : 0.9223204851150513\n",
            "*  *  *\n",
            "epoch 37 train loss : 0.27350020951934967\n",
            "epoch 37 test loss : 1.5783733325668527\n",
            "epoch 37 F1 : 0.9036139249801636\n",
            "epoch 37 Acc : 0.9809730648994446\n",
            "epoch 37 Pre : 0.9150651097297668\n",
            "*  *  *\n",
            "epoch 38 train loss : 0.2719415996088656\n",
            "epoch 38 test loss : 1.5847591599331627\n",
            "epoch 38 F1 : 0.9101771116256714\n",
            "epoch 38 Acc : 0.9823972582817078\n",
            "epoch 38 Pre : 0.9283416271209717\n",
            "*  *  *\n",
            "epoch 39 train loss : 0.2714070272979452\n",
            "epoch 39 test loss : 1.5765859175331984\n",
            "epoch 39 F1 : 0.9069450497627258\n",
            "epoch 39 Acc : 0.9816654324531555\n",
            "epoch 39 Pre : 0.9196023941040039\n",
            "*  *  *\n",
            "epoch 40 train loss : 0.26802230491312834\n",
            "epoch 40 test loss : 1.5790605665762214\n",
            "epoch 40 F1 : 0.9100262522697449\n",
            "epoch 40 Acc : 0.9823083281517029\n",
            "epoch 40 Pre : 0.9251202940940857\n",
            "*  *  *\n",
            "epoch 41 train loss : 0.2726648303110208\n",
            "epoch 41 Model Saved\n",
            "epoch 41 test loss : 1.5751617467856105\n",
            "epoch 41 F1 : 0.9132251143455505\n",
            "epoch 41 Acc : 0.9828914999961853\n",
            "epoch 41 Pre : 0.9257806539535522\n",
            "*  *  *\n",
            "epoch 42 train loss : 0.27172924878437127\n",
            "epoch 42 test loss : 1.5850589531886428\n",
            "epoch 42 F1 : 0.8983015418052673\n",
            "epoch 42 Acc : 0.9799841642379761\n",
            "epoch 42 Pre : 0.912497341632843\n",
            "*  *  *\n",
            "epoch 43 train loss : 0.26976292753524617\n",
            "epoch 43 test loss : 1.5762463445904888\n",
            "epoch 43 F1 : 0.9106121063232422\n",
            "epoch 43 Acc : 0.9823873043060303\n",
            "epoch 43 Pre : 0.9240143895149231\n",
            "*  *  *\n",
            "epoch 44 train loss : 0.26753451257372207\n",
            "epoch 44 test loss : 1.5808064469808265\n",
            "epoch 44 F1 : 0.9062284827232361\n",
            "epoch 44 Acc : 0.9815170764923096\n",
            "epoch 44 Pre : 0.9192095398902893\n",
            "*  *  *\n",
            "epoch 45 train loss : 0.26804152933328645\n",
            "epoch 45 test loss : 1.5846727377251735\n",
            "epoch 45 F1 : 0.9029695391654968\n",
            "epoch 45 Acc : 0.9809237122535706\n",
            "epoch 45 Pre : 0.9182364344596863\n",
            "*  *  *\n",
            "epoch 46 train loss : 0.2674546752657209\n",
            "epoch 46 test loss : 1.5871813976311986\n",
            "epoch 46 F1 : 0.9062613844871521\n",
            "epoch 46 Acc : 0.9815863370895386\n",
            "epoch 46 Pre : 0.9223054051399231\n",
            "*  *  *\n",
            "epoch 47 train loss : 0.26655085899555353\n",
            "epoch 47 test loss : 1.5755763250061228\n",
            "epoch 47 F1 : 0.9105038046836853\n",
            "epoch 47 Acc : 0.9823772311210632\n",
            "epoch 47 Pre : 0.9244367480278015\n",
            "*  *  *\n",
            "epoch 48 train loss : 0.2691857848467349\n",
            "epoch 48 test loss : 1.5754384737980516\n",
            "epoch 48 F1 : 0.9157554507255554\n",
            "epoch 48 Acc : 0.9833860993385315\n",
            "epoch 48 Pre : 0.92770916223526\n",
            "*  *  *\n",
            "epoch 49 train loss : 0.2644605998164301\n",
            "epoch 49 test loss : 1.5753668109072914\n",
            "epoch 49 F1 : 0.910465657711029\n",
            "epoch 49 Acc : 0.9823873043060303\n",
            "epoch 49 Pre : 0.925083577632904\n",
            "*  *  *\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict ={0:'T_shirt',1:'Trouser',2:'Pullover',3:'Dress',4:'Coat',5:'Sandal',6:'Shirt',7:'Sneaker',8:'Bag',9:'Boot'}\n",
        "dict[0]"
      ],
      "metadata": {
        "id": "nG0rAkPrJMmF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60cf7ad8-69f0-44a0-9850-8578f75f2ee2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T_shirt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num=44\n",
        "# x,y=trainX[num],trainy[num]\n",
        "x,y=testX[num],testy[num]\n",
        "x=x.unsqueeze(0)\n",
        "yy=model(x)\n",
        "x.squeeze(1)\n",
        "print(yy)\n",
        "# print(torch.max(yy)==yy)\n",
        "# print(y)\n",
        "print(f'it is a {dict[y]} and NN pridected that it is a {dict[int(torch.argmax(yy))]}')\n",
        "plt.imshow(np.asarray(np.transpose(x.cpu().squeeze(0).squeeze(0),(0,1)),dtype=np.uint8),cmap='gray')"
      ],
      "metadata": {
        "id": "rmUo5hgvGG_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "13f662bf-38ea-4178-f819-d8372fc2946b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  9.5120,  -3.0570,  14.3569,   5.4035,  16.5371, -32.7694,  22.0615,\n",
            "         -51.9949,  -2.5269, -32.9577]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "it is a Shirt and NN pridected that it is a Shirt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff9f9018c90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for i in range(10000):\n",
        "  # if(i%1000==0):\n",
        "  #   print(f'i is {i}')\n",
        "  if(torch.argmax(model(testX[i].unsqueeze(0)))!=testy[i]):\n",
        "    # print(i)\n",
        "    # if(count==5):\n",
        "    #   break\n",
        "    count+=1\n",
        "print(count)"
      ],
      "metadata": {
        "id": "GqctIGUMHdte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688fcaa0-46e7-4157-fb72-c97399159bf7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(m_los)\n",
        "print(cur_loss)"
      ],
      "metadata": {
        "id": "NdIghaD-X2Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2385506-3509-4a11-d6ae-7212b7f531c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5751617467856105\n",
            "tensor(1.5700, device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}